---
title: Motion Planning Augmented Reinforcement Learning for Long-Horizon Visual Robot Manipulation
author: GMKim
date: 2025-06-24 00:00:00 +0900
categories: [DRL]
tags: [DRL, Motion Planner, Long-horizon Task, Skill Chaining, Vision-Language Model, Object Detection, Habitat, Mobile Manipulator]
---

## Overview
---
- Motion Planning Augmented Reinforcement Learning for Long-Horizon Visual Robot Manipulation was a personal project I worked on in [Helper Lab](https://hlab.skku.edu/){:target="_blank"}, Sungkyunkwan university supervised by professor [Mun-Taek Choi](https://robot.skku.edu/robot_en/faculty.do?mode=view&perId=LZStrBwOQlgzg6gdgkgDwIYCkDCAhATAUzABhgHEBOHALQEEBeaoA%20&){:target="_blank"}.

- This research project is based on my Masterâ€™s thesis in [Intelligent Robotics](https://robot.skku.edu/robot_en/index.do){:target="_blank"}.

## Goal
---
- The objective of this study is to enhance the learning efficiency of Reinforcement Learning (RL) by incorporating physics-informed guidance, targeting a mobile manipulator in a simulated household environment.


## Description
---
- The methodology builds upon the framework proposed by Gu et al. in "Multi-Skill Mobile Manipulation for Object Rearrangement" ([Paper Link](https://arxiv.org/abs/2209.02778){:target="_blank"}).

- To address sparse rewards and inefficient exploration in RL, motion planning is incorporated into the reward function as guidance.

- The task is decomposed into pick, place, and navigation sub-skills, which are executed sequentially through point-based skill chaining.

- Vision-Language Model (VLM) augmented object detection is implemented by combining YOLOv7 with BLIP-2, enabling open-vocabulary semantic recognition.

- The system is developed using the Habitat Simulator.

- The robot setup is based on the Fetch Robot, consisting of a differential-drive mobile base and a 7-DOF arm equipped with a parallel-jaw gripper. RGB-D cameras are mounted on both the head and the arm.

- Note that abstract grasping is used, where physical contact dynamics are not modeled, and grasps are considered successful when within a specified positional threshold.

- As a result, each sub-skill demonstrated faster convergence in success rate compared to the baseline distance-based methods without motion planning augmentation.

- Furthermore, the cumulative success rate for long-horizon tasks reached a relatively high value of 0.72.


![mprl_1](/assets/img/mprl_1.png){:width="80%" height="auto" :style="border:1px solid #eaeaea; border-radius: 7px; padding: 0px;" }
![mprl_2](/assets/img/mprl_2.png){:width="60%" height="auto" :style="border:1px solid #eaeaea; border-radius: 7px; padding: 0px;" }
![mprl_3](/assets/img/mprl_3.png){:width="60%" height="auto" :style="border:1px solid #eaeaea; border-radius: 7px; padding: 0px;" }


## References
---
- [Youtube Link 1](https://www.youtube.com/watch?v=Ze-CwOL-IRc){:target="_blank"}

- [Youtube Link 2](https://www.youtube.com/watch?v=3ItsuBOSUNQ){:target="_blank"}

- [Paper Link](https://dcollection.skku.edu/srch/srchDetail/000000183923?localeParam=en){:target="_blank"}

